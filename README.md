[![](https://img.shields.io/badge/DOI-10.17632/p9y27y66jb.1-blue)](https://data.mendeley.com/datasets/p9y27y66jb/1)
[![](https://img.shields.io/badge/DOI-10.1109/IranianCEE.2012.6292612-blue)](https://doi.org/10.1109/IranianCEE.2012.6292612)

# Subject-Specific Feature Extraction Approach for a Three-Class Motor Imagery-Based Brain-Computer Interface Enabling Navigation in a Virtual Home: Open Access Framework
Brain-Computer Interface (BCI) is a system to assist disabled people by creating a new communication channel between the brain and computer. BCI can be designed based on various electrophysiological sources. Motor Imagery (MI)-based BCI enables users with motor disabilities to communicate with the environment more naturally. Subject training in an MI-based BCI is an important factor. For this purpose, various bio-feedbacks have been used in the BCI research area. In this work, we show how a user can navigate in a virtual home after cue-based training with feedback and applying a subject-specific feature extraction approach. The task of the subject in the virtual home is to perform left hand, right hand and feet motor imagery to navigate from the start station to the end station as quickly as possible. The total BCI and virtual environment are implemented in MATLAB and control signals are generated by analyzing three bipolar channels only.

This repo describes a framework known as MI-EEG-BCI-VR, integrating Motor Imagery (MI) and electroencephalography (EEG)-based Brain-Computer Interface (BCI) technologies, enabling users to navigate Virtual Environments (VEs) by imagining movements. The subject-specific feature extraction approach was employed.
To enhance user-friendliness and facilitate easy interaction, this repo contains interactive MATLAB-based Graphical User Interfaces (GUIs) for data acquisition, processing, visualization, and running tasks.

##  Cue-Based Training without Feedback
![](/ppt/WithoutFeedback.gif)

## Subject-specific Feature and Classifier Selection
* Features
  * (Higher-order) Statistical Features (Ergodicity Assumption)
     * Mean, Mean Absolute Value (MAV), Standard Deviation, Moments, Cumulants, Correlation, and Form Factor.
  * Transform-based
     * Fourier, Discrete Sine and Cosine, Short-time Fourier Transform (STFT), and Wavelet.
  * Parametric Model
     * Autoregressive (AR)(Burg, Forward-Backward, Geometrric, Least-squares, Yule-Walker), Moving-average (MA), and Autoregressive Moving-average (ARMA).
  * Frequency Band Power
     * Fourier, STFT, AR (Burg, Covariance, Modified Covariance, Eigenvector, Multitaper, MUSIC, Yule-Walker), Welch, and Periodogram.
  * Entropy
     * Shannon, Renyi, Tsallis, Approximate, and Sample.
* Classifiers
   * Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), Mahalanobis Discriminant Analysis (MDA), Support Vector Machine (SVM), Multilayer Perceptron (MLP), Naive Bayes, K-Nearest Neighbour (KNN), Error Correcting Output Codes (ECOC), and Decision Tree (DT).
![](/ppt/GUI_Analysis.gif)

## Cue-Based Training with Feedback
![](/ppt/WithFeedback.gif)

## Virtual Home Navigation
![](/ppt/VE-tour.gif)
![](/ppt/VE-tour-subject.gif)
![](/ppt/VE-task.gif)

## VR in MI-based EEG-based BCI (MI-EEG-BCI-VR)
![Slide1](/ppt/Slide1.PNG)
![Slide2](/ppt/Slide2.PNG)
![Slide3](/ppt/Slide3.PNG)
![Slide4](/ppt/Slide4.PNG)
![Slide5](/ppt/Slide5.PNG)
![Slide6](/ppt/Slide6.PNG)
![Slide7](/ppt/Slide7.PNG)
![Slide8](/ppt/Slide8.PNG)
![Slide9](/ppt/Slide9.PNG)
![Slide10](/ppt/Slide10.PNG)
![Slide11](/ppt/Slide11.PNG)
![Slide12](/ppt/Slide12.PNG)
![Slide13](/ppt/Slide13.PNG)
![Slide14](/ppt/Slide14.PNG)
![Slide15](/ppt/Slide15.PNG)
![Slide16](/ppt/Slide16.PNG)
![Slide17](/ppt/Slide17.PNG)
![Slide18](/ppt/Slide18.PNG)
![Slide19](/ppt/Slide19.PNG)
![Slide20](/ppt/Slide20.PNG)
![Slide21](/ppt/Slide21.PNG)
![Slide22](/ppt/Slide22.PNG)
![Slide23](/ppt/Slide23.PNG)
![Slide24](/ppt/Slide24.PNG)
![Slide25](/ppt/Slide25.PNG)
![Slide26](/ppt/Slide26.PNG)
![Slide27](/ppt/Slide27.PNG)
![Slide28](/ppt/Slide28.PNG)
![](/ppt/WithoutFeedback.gif)
![Slide29](/ppt/Slide29.PNG)
![](/ppt/GUI_Analysis.gif)
![Slide30](/ppt/Slide30.PNG)
![](/ppt/WithFeedback.gif)
![Slide31](/ppt/Slide31.PNG)
![Slide32](/ppt/Slide32.PNG)
![Slide33](/ppt/Slide33.PNG)
![Slide34](/ppt/Slide34.PNG)
![Slide35](/ppt/Slide35.PNG)
![Slide36](/ppt/Slide36.PNG)
![Slide37](/ppt/Slide37.PNG)
![Slide38](/ppt/Slide38.PNG)
![Slide39](/ppt/Slide39.PNG)
![Slide40](/ppt/Slide40.PNG)
![Slide41](/ppt/Slide41.PNG)
![Slide42](/ppt/Slide42.PNG)
![](/ppt/VE-tour.gif)
![](/ppt/VE-tour-subject.gif)
![](/ppt/VE-task.gif)
![Slide43](/ppt/Slide43.PNG)
![Slide47](/ppt/Slide47.PNG)
![Slide49](/ppt/Slide49.PNG)
![Slide52](/ppt/Slide52.PNG)
![Slide53](/ppt/Slide53.PNG)

# How to cite
* **F. Afdideh**, M. B. Shamsollahi, “Subject-Specific Feature Extraction Approach for a Three-Class Motor Imagery-Based Brain-Computer Interface Enabling Navigation in a Virtual Home: Open Access Framework,” [under review](https://github.com/fardinafdideh/subject-specific-EEG-MI-BCI-VR-Journal).
* **F. Afdideh**, M. B. Shamsollahi, (2024), “MI-EEG-BCI-VR”, [Mendeley Data](https://data.mendeley.com/datasets/p9y27y66jb/1), V1, doi: 10.17632/p9y27y66jb.1.
* **F. Afdideh**, M. B. Shamsollahi, S. N. Resalat, “Development of a MATLAB-Based Toolbox for Brain Computer Interface Applications in Virtual Reality,” Iranian Conference on Electrical Engineering ([ICEE](https://ieeexplore.ieee.org/document/6292612)), pp. 1579-1583, 2012, doi: 10.1109/IranianCEE.2012.6292612. 
* **F. Afdideh**. Brain-Computer Interface for Navigation in Virtual Environments. Electrical Engineering. Sharif University of Technology, 2011. Persian. ‭05-41575.
